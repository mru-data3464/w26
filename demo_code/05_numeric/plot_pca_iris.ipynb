{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Principal Component Analysis (PCA) on Iris Dataset\n",
        "\n",
        "This example shows a well known decomposition technique known as Principal Component Analysis (PCA) on the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
        "\n",
        "This dataset is made of 4 features: sepal length, sepal width, petal length, petal width. We use PCA to project this 4 feature space into a 3-dimensional space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: The scikit-learn developers\n",
        "# SPDX-License-Identifier: BSD-3-Clause"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Iris dataset\n",
        "\n",
        "The Iris dataset is directly available as part of scikit-learn. It can be loaded using the :func:`~sklearn.datasets.load_iris` function. With the default parameters, a :class:`~sklearn.utils.Bunch` object is returned, containing the data, the target values, the feature names, and the target names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris(as_frame=True)\n",
        "print(iris.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot of pairs of features of the Iris dataset\n",
        "\n",
        "Let's first plot the pairs of features of the Iris dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Rename classes using the iris target names\n",
        "iris.frame[\"target\"] = iris.target_names[iris.target]\n",
        "_ = sns.pairplot(iris.frame, hue=\"target\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each data point on each scatter plot refers to one of the 150 iris flowers in the dataset, with the color indicating their respective type(Setosa, Versicolor, and Virginica).\n",
        "\n",
        "You can already see a pattern regarding the Setosa type, which is easily identifiable based on its short and wide sepal. Only considering these two dimensions, sepal width and length, there's still overlap between the Versicolor and Virginica types.\n",
        "\n",
        "The diagonal of the plot shows the distribution of each feature. We observe that the petal width and the petal length are the most discriminant features for the three types.\n",
        "\n",
        "## Plot a PCA representation\n",
        "Let's apply a Principal Component Analysis (PCA) to the iris dataset and then plot the irises across the first three principal components. This will allow us to better differentiate among the three types!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# unused but required import for doing 3d projections with matplotlib < 3.2\n",
        "import mpl_toolkits.mplot3d  # noqa: F401\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "fig = plt.figure(1, figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection=\"3d\", elev=-150, azim=110)\n",
        "\n",
        "pca = PCA()\n",
        "X_reduced = pca.fit_transform(iris.data)\n",
        "scatter = ax.scatter(\n",
        "    X_reduced[:, 0],\n",
        "    X_reduced[:, 1],\n",
        "    X_reduced[:, 2],\n",
        "    c=iris.target,\n",
        "    s=40,\n",
        ")\n",
        "\n",
        "ax.set(\n",
        "    title=\"First three principal components\",\n",
        "    xlabel=\"1st Principal Component\",\n",
        "    ylabel=\"2nd Principal Component\",\n",
        "    zlabel=\"3rd Principal Component\",\n",
        ")\n",
        "ax.xaxis.set_ticklabels([])\n",
        "ax.yaxis.set_ticklabels([])\n",
        "ax.zaxis.set_ticklabels([])\n",
        "\n",
        "# Add a legend\n",
        "legend1 = ax.legend(\n",
        "    scatter.legend_elements()[0],\n",
        "    iris.target_names.tolist(),\n",
        "    loc=\"upper right\",\n",
        "    title=\"Classes\",\n",
        ")\n",
        "ax.add_artist(legend1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PCA will create 3 new features that are a linear combination of the 4 original features. In addition, this transformation maximizes the variance. With this transformation, we can identify each species using only the first principal component.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extra stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at just the first two components\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(\n",
        "    X_reduced[:, 0],\n",
        "    X_reduced[:, 1],\n",
        "    c=iris.target\n",
        ")\n",
        "ax.set_aspect(\"equal\")\n",
        "plt.title(\"First two principal components\")\n",
        "plt.xlabel(\"1st Principal Component\")\n",
        "plt.ylabel(\"2nd Principal Component\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the explained variance ratio\n",
        "plt.figure()\n",
        "plt.plot(range(1, 5), pca.explained_variance_ratio_)\n",
        "plt.ylabel(\"Variance explained\")\n",
        "plt.xlabel(\"Component\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# What is that first one?\n",
        "plt.bar(range(4), pca.components_[0], width=0.2)\n",
        "plt.xticks(range(4), iris.feature_names, rotation=45)\n",
        "plt.ylabel(\"Weight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LDA\n",
        "Linear Discriminant Analysis (LDA) is similar, but maximizes between-class variance instead of overall variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# What about LDA instead?\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "X_lda = lda.fit_transform(iris.data, iris.target)\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(\n",
        "    X_lda[:, 0],\n",
        "    X_lda[:, 1],\n",
        "    c=iris.target\n",
        ")\n",
        "ax.set_aspect(\"equal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare PCA and LDA weights\n",
        "import numpy as np\n",
        "\n",
        "plt.bar(np.arange(4)-0.1, pca.components_[0], width=0.2, label=\"PCA\")\n",
        "plt.bar(np.arange(4)+0.1, lda.coef_[0] / lda.coef_[0].sum(), width=0.2, label=\"LDA\")\n",
        "plt.xticks(range(4), iris.feature_names, rotation=45)\n",
        "plt.ylabel(\"Weight\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the explained variance ratio\n",
        "plt.figure()\n",
        "plt.plot(range(1, 5), pca.explained_variance_ratio_, label=\"PCA\")\n",
        "plt.plot(range(1, 3), lda.explained_variance_ratio_, \"o\", label=\"LDA\")\n",
        "plt.ylabel(\"Variance explained\")\n",
        "plt.xlabel(\"Component\")\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

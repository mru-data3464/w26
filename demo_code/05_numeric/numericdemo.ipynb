{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06de18df",
   "metadata": {},
   "source": [
    "## Code for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    Normalizer,\n",
    "    FunctionTransformer,\n",
    "    PowerTransformer,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=123456)\n",
    "x = rng.normal(5, 2, 1000)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].hist(x, bins=50)\n",
    "axes[0].set_title(\"Original data\")\n",
    "axes[1].hist((x - x.mean()) / x.std(), bins=50)\n",
    "axes[1].set_title(\"Standardized\")\n",
    "axes[2].hist((x - x.min()) / (x.max() - x.min()), bins=50)\n",
    "axes[2].set_title(\"Normalized\")\n",
    "\n",
    "plt.savefig(\"../../static/img/05-scaling.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60031c5",
   "metadata": {},
   "source": [
    "## Fake data to demonstrate scaling and nonlinear transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some fake count data\n",
    "# From Intro to Machine Learning with Python\n",
    "X_org = rng.normal(size=(1000, 3))\n",
    "X = rng.poisson(10 * np.exp(X_org))\n",
    "\n",
    "plt.hist(X[:, 1], bins=50)\n",
    "\n",
    "plt.xlabel(\"Times per day checking D2L\")\n",
    "plt.ylabel(\"Number of days\")\n",
    "\n",
    "plt.savefig(\"../../static/img/05-counts.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e7af0",
   "metadata": {},
   "source": [
    "## Side comment on the central limit theorem\n",
    "Sums of independent and identically distributed random variables converge to normal as number of samples increases.\n",
    "\n",
    "As soon as one of those criteria are missing, you can't count on it anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff411b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLT version\n",
    "X_c = np.zeros(1000)\n",
    "for i in range(len(X)):\n",
    "    X_c[i] = rng.poisson(X[:, 1].mean(), size=50).mean()\n",
    "\n",
    "plt.hist(X_c, bins=50)\n",
    "\n",
    "plt.xlabel(\"Average times per day checking D2L\")\n",
    "plt.ylabel(\"Number of days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65477e9c",
   "metadata": {},
   "source": [
    "## Back to the fake data\n",
    "Create a fake (scalar) output using the \"counts\" data X (which is actually a matrix of 3 features) as input.\n",
    "\n",
    "Note that the data generation doesn't actually use the count data directly, but instead is a linearly weighted combination of the normally distributed random samples that were used as parameters in the poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some more fake features and a fake X\n",
    "# Repeated runs of the same cell results in different values unless we re-seed\n",
    "rng = np.random.default_rng(seed=42)\n",
    "w = rng.normal(size=3)\n",
    "y = X_org.dot(w)\n",
    "\n",
    "# the usual split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "axes[0].set_ylabel(\"$y$\")\n",
    "for i in range(3):\n",
    "    axes[i].scatter(X_train[:, i], y_train, alpha=0.3)\n",
    "    axes[i].set_xlabel(f\"$x_{i}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3808ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a regression model on the raw data using stochastic gradient descent\n",
    "model = SGDRegressor()\n",
    "cross_val_score(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add on the preprocessing pipeline\n",
    "pipeline = make_pipeline(\n",
    "    # FunctionTransformer(np.log1p), # log + 1\n",
    "    StandardScaler(),\n",
    "    model,\n",
    ")\n",
    "\n",
    "cross_val_score(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a584b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_est = pipeline.predict(X_train)\n",
    "plt.scatter(y_est, y_train)\n",
    "plt.xlabel(r\"Predicted $\\hat{y}$\")\n",
    "plt.ylabel(\"True $y$\")\n",
    "plt.text(2, -3, f\"MSE = {np.mean((y_train - y_est)**2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246cb9a0",
   "metadata": {},
   "source": [
    "## Mixed data types: Categorical and numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisit the OKCupid data\n",
    "df = pd.read_csv(\"../04_categorical/profiles_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target: job is \"other\" or \"rather not say\"\n",
    "df[\"job\"].value_counts()\n",
    "df[\"mystery_job\"] = df[\"job\"].apply(lambda j: j in [\"other\", \"rather not say\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac150d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features to use in the model\n",
    "numeric_features = [\"age\", \"height\", \"income\"]\n",
    "cat_features = [\"drinks\", \"education\", \"sex\"]\n",
    "\n",
    "# For now, drop features with missing values\n",
    "# We'll look at imputation later\n",
    "df.dropna(subset=numeric_features + cat_features, inplace=True)\n",
    "\n",
    "X = df[numeric_features + cat_features]\n",
    "y = df[\"mystery_job\"].astype(float)\n",
    "\n",
    "# split!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=df[\"mystery_job\"], random_state=12345\n",
    ")\n",
    "\n",
    "# count how many in each class\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trickier encoders\n",
    "drink_enc = OrdinalEncoder(\n",
    "            categories=[\n",
    "                [\n",
    "                    \"not at all\",\n",
    "                    \"rarely\",\n",
    "                    \"socially\",\n",
    "                    \"often\",\n",
    "                    \"very often\",\n",
    "                    \"desperately\",\n",
    "                ]\n",
    "            ],\n",
    "            handle_unknown=\"use_encoded_value\",\n",
    "            unknown_value=-1,\n",
    "        )\n",
    "\n",
    "# This took a while mucking around to figure out the right magic between df/series\n",
    "def split_edu(df):\n",
    "    df[\"education\"] = df[\"education\"].str.split(\" \")\n",
    "    return df[\"education\"]\n",
    "\n",
    "edu_enc = make_pipeline(\n",
    "        FunctionTransformer(split_edu, validate=False),\n",
    "        FeatureHasher(n_features=16, input_type=\"string\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the preprocessing pipeline\n",
    "preprocessor = make_column_transformer(\n",
    "    (PowerTransformer(method=\"yeo-johnson\"), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\"]),\n",
    "    (drink_enc, [\"drinks\"]),\n",
    "    (edu_enc, [\"education\"]),\n",
    ")#.set_output(transform=\"pandas\")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee79b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pro = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works with set_output(transform=\"pandas\")\n",
    "# pd.plotting.scatter_matrix(X_pro, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add on a model!\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    SGDClassifier(),\n",
    ")\n",
    "\n",
    "cross_val_score(pipeline, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
